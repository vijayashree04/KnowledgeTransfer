# ğŸ“š Centralized Knowledge Transfer Hub

A modern, AI-powered knowledge management system that enables teams to upload, organize, and query documents using semantic search. Built with Streamlit, Supabase, Pinecone, and Google Gemini AI.

## âœ¨ Features

- **ğŸ“¤ Document Upload**: Support for multiple file formats (PDF, DOCX, TXT, MD, PY, JS, JSON)
- **ğŸ¤– AI-Powered Chatbot**: Ask questions and get answers based on your team's documents using semantic search
- **ğŸ” Vector Search**: Pinecone integration for intelligent document retrieval
- **ğŸ“ Automatic Summarization**: AI-generated summaries for uploaded documents
- **ğŸ‘¥ Team Management**: Multi-team support with access codes and team leads
- **ğŸ” Secure Authentication**: User authentication and team-based access control
- **â˜ï¸ Cloud Storage**: Supabase integration for scalable document storage
- **ğŸ“Š Document Repository**: View and manage all team documents in one place

## ğŸ› ï¸ Tech Stack

- **Frontend**: Streamlit
- **Backend**: Python 3.11+
- **Database**: Supabase (PostgreSQL)
- **Storage**: Supabase Storage
- **Vector Database**: Pinecone (optional, for semantic search)
- **AI/ML**: Google Gemini (text-embedding-004, gemini-2.5-flash)
- **Document Processing**: pypdf, python-docx

## ğŸ“‹ Prerequisites

- Python 3.11 or higher
- Supabase account and project
- Google Gemini API key
- Pinecone account (optional, for vector search)

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd KnowledgeTransfer
```

### 2. Create Virtual Environment

```bash
python -m venv venv
```

**Activate the virtual environment:**

- **Windows PowerShell:**
  ```powershell
  .\venv\Scripts\Activate.ps1
  ```

- **Windows CMD:**
  ```cmd
  venv\Scripts\activate.bat
  ```

- **Mac/Linux:**
  ```bash
  source venv/bin/activate
  ```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

## âš™ï¸ Configuration

### 1. Create `.env` File

Create a `.env` file in the project root with the following variables:

```env
# Supabase Configuration (Required)
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_KEY=your-anon-public-key-here
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-here

# Gemini API Key (Required)
GEMINI_API_KEY=your-gemini-api-key-here

# Pinecone Configuration (Optional - for vector search)
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_INDEX_NAME=kt-docs
```

### 2. Set Up Supabase Database

Run the SQL schema in your Supabase SQL Editor:

```bash
# See supabase_schema.sql for the complete schema
```

The schema includes:
- `teams` table for team management
- `users` table for user authentication
- `documents` table for document metadata

### 3. Create Supabase Storage Bucket

1. Go to Supabase Dashboard â†’ Storage
2. Create a bucket named `documents`
3. Set appropriate permissions (public or private based on your needs)

### 4. Set Up Pinecone Index (Optional)

If using vector search:

1. Create a Pinecone account at [pinecone.io](https://www.pinecone.io)
2. Create an index with:
   - **Name**: `kt-docs` (or your preferred name)
   - **Dimension**: `768` (for Gemini text-embedding-004)
   - **Metric**: `cosine`

## ğŸƒ Running the Application

```bash
streamlit run main.py
```

The application will open in your browser at `http://localhost:8501`

## ğŸ“– Usage

### First Time Setup

1. **Create a Team** (via Supabase dashboard or API):
   - Team name
   - Access code (for team members to join)
   - Team lead email

2. **Sign Up**:
   - Click "Sign Up" on the login page
   - Enter your name, email, and password
   - Create your account

3. **Login**:
   - Enter your email and password
   - Enter your team's access code
   - You'll be redirected to the main dashboard

### Uploading Documents

1. Go to the **"ğŸ“¤ Upload Documents"** tab
2. Click "Choose a file" and select your document
3. Click "Process & Upload"
4. The document will be:
   - Uploaded to Supabase Storage
   - Indexed in Pinecone (if enabled)
   - Summarized using AI
   - Stored in the database

### Using the Chatbot

1. Go to the **"ğŸ¤– KT Chatbot"** tab
2. Type your question in the chat input
3. The chatbot will:
   - Search for relevant document chunks using vector search
   - Generate an answer based on the retrieved context
   - Display the response

### Viewing Documents

1. Go to the **"ğŸ“ Document Summaries"** tab
2. Browse all documents uploaded by your team
3. Click on any document to view:
   - Summary
   - Content preview
   - Upload information

### Team Management (Team Leads Only)

Team leads can:
- View team information
- Update team lead assignment
- Delete documents

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º Supabase (Database & Storage)
         â”‚    â”œâ”€â”€ Teams
         â”‚    â”œâ”€â”€ Users
         â”‚    â””â”€â”€ Documents
         â”‚
         â”œâ”€â”€â–º Pinecone (Vector Database)
         â”‚    â””â”€â”€ Document Embeddings
         â”‚
         â””â”€â”€â–º Google Gemini AI
              â”œâ”€â”€ Text Embeddings
              â”œâ”€â”€ Document Summarization
              â””â”€â”€ Chat Responses
```

## ğŸ“ Project Structure

```
KnowledgeTransfer/
â”œâ”€â”€ main.py                 # Main Streamlit application
â”œâ”€â”€ auth.py                 # Authentication logic
â”œâ”€â”€ document_store.py       # Document management
â”œâ”€â”€ vector_store.py         # Pinecone vector search
â”œâ”€â”€ gemini_utils.py         # Gemini AI integration
â”œâ”€â”€ team_store.py           # Team management
â”œâ”€â”€ user_store.py           # User management
â”œâ”€â”€ supabase_config.py      # Supabase configuration
â”œâ”€â”€ supabase_schema.sql     # Database schema
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â””â”€â”€ .env                   # Environment variables (create this)
```

## ğŸ”§ Configuration Options

### Chunking Parameters

Documents are automatically chunked for vector search. You can adjust these in `vector_store.py`:

```python
def _chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200):
    # Adjust chunk_size and overlap as needed
```

### Retrieval Parameters

Adjust the number of chunks retrieved in `document_store.py`:

```python
matches = vector_store.query_similar_documents(
    query_text=query,
    team_id=str(team_id),
    team_name=team_name,
    top_k=10  # Number of chunks to retrieve
)
```

## ğŸ› Troubleshooting

### "Supabase is not configured" Error

- Ensure `.env` file exists with `SUPABASE_URL` and `SUPABASE_KEY`
- Verify the Supabase project is active
- Check that the database schema is set up correctly

### "Pinecone not available" Warning

- This is normal if Pinecone is not configured
- The system will fall back to using all documents
- To enable: add `PINECONE_API_KEY` and `PINECONE_INDEX_NAME` to `.env`

### Document Upload Fails

- Check Supabase Storage bucket exists and is accessible
- Verify file size is within limits
- Ensure proper permissions on the storage bucket

### Chatbot Not Working

- Verify Gemini API key is set correctly
- Check that documents have been indexed in Pinecone (if using vector search)
- Ensure documents contain text content (not just images)

## ğŸ“ Supported File Formats

- **Text**: `.txt`, `.md`, `.py`, `.js`, `.json`
- **Documents**: `.pdf`, `.docx`, `.doc`
- **Maximum file size**: 200MB

## ğŸ”’ Security Considerations

- Store API keys securely in `.env` file (never commit to version control)
- Use Supabase Row Level Security (RLS) for data access control
- Prefer `SUPABASE_KEY` (anon key) over service role key for client operations
- Regularly rotate API keys

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

[Add your license here]

## ğŸ™ Acknowledgments

- [Streamlit](https://streamlit.io/) for the web framework
- [Supabase](https://supabase.com/) for backend infrastructure
- [Pinecone](https://www.pinecone.io/) for vector search
- [Google Gemini](https://ai.google.dev/) for AI capabilities

## ğŸ“ Support

For issues and questions, please open an issue on the repository.

---

**Built with â¤ï¸ for efficient knowledge transfer**

